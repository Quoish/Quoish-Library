#机器学习 #人工智能
# 人工智能三大学派
## 符号主义（Symbolicism）
符号主义，又称逻辑主义、心理学派或计算机学派，是人工智能最早的主流学派。其核心思想源于“物理符号系统假说”，即：智能的基础是知识，智能活动的过程就是对符号的表示和运算。 只要在计算机中建立了适当的符号系统，并基于逻辑规则进行推理，就能实现人工智能。
其基本思路是：先为机器设定知识和规则，然后让机器应用这些规则去解决具体问题。
其优点是，推理过程清晰、透明、可解释（白盒模型），易于表达明确的逻辑和知识。
其缺点是， “知识工程瓶颈”——如何让机器获取海量知识是一项极其艰巨的任务。许多人类常识和隐性知识难以用明确的符号规则表示。系统缺乏学习能力，灵活性差。
## 连接主义（Connectionism）
连接主义，又称仿生学派或生理学派。其核心思想是：智能活动是由大量简单单元（神经元）通过复杂互连后，并行运行的结果。 它主张通过模拟人脑神经网络的结构和机制来实现人工智能。他们认为，智能不是来自预设的规则，而是从海量数据的统计规律中**涌现**出来的。
其基本思路是：不预先设定规则，而是构建一个类似神经元的网络结构，通过大量数据对其进行训练（调节网络连接权重），让机器自己“学习”出解决问题的模型。
其优点是，拥有强大的学习能力和表征能力，特别擅长处理感知类任务（如图像识别、语音识别、自然语言处理），对模糊和不确定性问题有很好的容错性。
其缺点是，模型是“黑盒”，决策过程难以解释和理解（可解释性差）；需要海量的标注数据和巨大的计算资源；推理能力较弱。
## 行为主义（Actionism）
行为主义，又称进化主义或控制论学派。其核心思想是：智能取决于感知和行动，是在与环境的交互中“进化”出来的。 智能不需要知识，不需要表示，不需要推理，只需要在环境中做出适当的行为即可。
其基本思路是：设计一个智能体（Agent），为其设定一些简单的基本行为规则（如避障、前进）、奖惩机制（强化学习），然后将其置于真实或模拟的环境中，让其通过不断试错来学习最优策略。
其优点是，强调与环境的实时交互，适合解决序列决策问题（如机器人控制、自动驾驶、AlphaGo下围棋）。具有自学习和自适应能力。
其缺点是，学习过程效率低，需要大量试错；在复杂环境中难以收敛；对状态和奖励函数的设计依赖性强。
# 人工神经元
最初，科学家在构建神经网络时的灵感来自于生物上的神经元。神经元从树突接收信号，然后从轴突输出信号，众多神经元组成一个巨大的网络之后，就可以实现非常复杂的功能。即使对于单个神经元的运作机制，神经科学并没有完全的解答，但是利用这种“涌现”的思想，我们可以类似地，通过搭建一个网络，实现复杂的功能。
在计算机中，用来模拟神经元的就是一个[[数学物理/机器学习]]模块，或者回归计算单元。人工神经网络的基本单位是 “人工神经元”，也叫 “节点” 或 “单元”。
一个简单的神经元工作方式如下：
1. 接收输入（Inputs）：它接收来自外部或多个上游神经元的信号（数据），记为$\vec{x}=(x_{1},x_{2},\dots,x_{n})$。
2. 加权求和（Weighted Sum）：每个输入都有一个权重（Weight），记为$\vec{w}=(w_{1},w_{2},\dots,w_{n})$​。权重代表了该输入的重要性。神经元将所有输入与其对应的权重相乘后求和，并加上一个偏置（Bias）项$b$（用于调整模型的灵活性）。
    - $加权和 = \vec{w}\cdot \vec{x} + b$
3. 通过激活函数（Activation Function）：将上一步的加权和输入到一个激活函数中。这个函数的作用是引入非线性因素，让神经网络可以学习并模拟非常复杂的模式（如果没有它，神经网络就只是一个简单的线性回归模型）。常见的激活函数有 Sigmoid、ReLU 等。
	-  $输出 = \mathrm{ActivateFunc}(加权和)$
# 神经网络的结构
单个神经元能力有限，但将大量的神经元相互连接成网络，就能产生强大的能力。神经网络通常由三层组成：
1. 输入层（Input Layer）：负责接收原始数据。比如，一张图片的所有像素值、一段文字的数值化表示等。
2. 隐藏层（Hidden Layers）：介于输入和输出层之间。这是神经网络的核心部分，负责对输入数据进行层层抽象和特征提取。一个神经网络可以有一个或多个隐藏层，层数越多、每层的神经元越多，网络就越“深”、越复杂（这就是“深度学习”中“深度”的由来）。
3. 输出层（Output Layer）：产生最终的计算结果。根据任务不同，输出可以是一个数值（如预测房价）、一个概率分布（如图片属于“猫”或“狗”的概率）、一组序列（如翻译后的句子）等。

信息从输入层开始，逐层向前传递，最终到达输出层，这个过程称为 “前向传播”（Forward Propagation）。
![[神经网络的层.png]]
在前向传播的过程中，每一层的单元都会提取出一些特征。层级越深，所提取的特征就越具有概括性。
![[人脸识别的例子.png]]
# 神经网络的训练
神经网络学习的过程就是不断调整网络中所有神经元的权重（Weights）和偏置（Biases） 的过程，以使网络的输出尽可能接近我们期望的正确答案。
## 损失函数
损失函数（Lose Function），也称为代价函数（Cost Function），是衡量神经网络预测输出与真实值之间差距的函数。损失值越小，说明模型的预测越准确。
每经过一轮前向传播之后，会计算其损失函数，来评估此轮预测的准确性。
常见的损失函数有：
- 均方误差函数（MSE，Mean Squared Error）：主要用于回归问题，预测一个连续值$$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$
- 交叉熵函数：主要用于分类问题，在分类任务中，它通常比MSE更有效，性能更好
## 反向传播
接下来我们需要通过优化算法来使得损失函数最小化，最常见的做法是使用梯度下降法。
这个过程中需要计算损失函数对各个参数的导数。
直接计算导数会非常复杂，所以通常采用链式法则逐层计算：
先计算最终输出对倒数第一层隐藏层输出的导数，然后再计算倒数第一层输出对倒数第二层输出的导数，依次直到第一层，这样从后向前计算导数的过程称作反向传播（Backward Propagation）。
得到梯度之后，再利用梯度下降公式：
$$W_{new} = W_{old} - \alpha \cdot \frac{\partial Loss}{\partial W_{old}}$$其中$\alpha$是学习率。依次迭代，就可以使得损失函数最小化。
![[反向传播.png]]
反复的前向传播和反向传播，这就是神经网络的训练过程。
# 泛化能力
泛化能力（Generalization Ability）指的是一个机器学习模型在从未见过的新数据上表现良好的能力。
>**过拟合** 是机器学习中最常见的问题。它发生在模型过于紧密地匹配训练数据，以至于学习了训练数据中的噪声（noise） 和细节（details），而不是底层的一般规律。导致的结果是，它在训练数据上表现极好，但在新数据上表现很差。

过拟合问题会削弱模型的泛化能力，影响模型的功能。
常见阻止过拟合的方法：
- 获取更多数据：更多的数据能让模型接触到更广泛的情况，更容易发现真正的规律，而不是局限于少量数据中的偶然特征。这是最有效的方法，但通常也最难或最昂贵。
- 数据增强：当获取新数据成本太高时，对现有的训练数据进行一些合理的变换来创造“新”数据。主要用于图像领域，如对图像裁剪，旋转等操作。
- 简化模型：即主动降低模型的复杂度。对于神经网络，则减少层数或每层的神经元数量；对于决策树，则降低树的深度、剪枝。
- 正则化：在损失函数中增加一个额外的**惩罚项**，用于惩罚过大的模型权重。权重越大通常意味着模型越复杂。
	- L1正则化：惩罚项为$\sum_{i}|w_{i}|$，倾向于产生稀疏的权重矩阵（即很多权重变为0），可用于特征选择。
	- L2正则化：惩罚项为$\sum_{i}w_{i}^2$使权重值趋于变小、分布更均匀，是最常用的正则化方法。
- Dropout：在训练过程中，随机地“丢弃”网络中的一部分神经元（暂时将其输出设为0），这防止了神经元之间形成过强的、固定的依赖关系（这种依赖可能是对训练数据噪声的拟合）
- 早停：在训练过程中，持续监控模型在验证集上的性能。当验证集上的错误率不再下降反而开始上升时（即模型开始过拟合训练集），就立即停止训练。
# 神经网络的结构
## 全连接神经网络
全连接神经网络又称多层感知机、深度前馈网络，这是最基础、最经典的神经网络结构。每一层的每一个神经元都与下一层的每一个神经元相连接。
缺陷：由于是全连接，参数量非常巨大（参数数量 = 本层神经元数 × 下一层神经元数）。这对于高维输入（如图像）来说计算成本极高且容易过拟合。
实际运用中通常用于神经网络的最后几层，将学习到的特征综合起来做出最终决策。
## 卷积神经网络
卷积神经网络（Convolutional Neural Networks, CNN）是专门为处理网格状数据（如图像、音频、时间序列）而设计的神经网络。
它通过两个核心概念来极大减少参数数量并有效提取空间特征：局部连接和权值共享。
- 局部感知：传统神经网络是全连接的，即每个神经元都要看整个图像。而CNN认为，图像中一个像素点只与其附近区域（如3×3范围内）的像素点强相关，与距离很远的像素点几乎无关。因此，每个神经元只需感受图像的**一小块局部区域**即可，后续再将不同局部区域的信息综合起来得到全局信息。
- 权值共享：同一个特征（例如“垂直边缘”），可能出现在图像中的任何位置。CNN使用**相同的卷积核**（一组固定的权重）扫描整张图像。这意味着无论这个特征出现在左上角还是右下角，都由同一个卷积核来检测，而不需要为每个位置都学习一个单独的检测器。这极大地减少了参数数量。
- 空间下采样：通过池化层逐渐降低数据的空间尺寸（高度和宽度），减少计算量，同时保持特征的有效性，并赋予模型一定的**平移不变性**（即目标在图像中轻微移动，仍能被识别）。
一个典型的CNN由一系列层堆叠而成。其核心结构序列通常是：  
>**输入层 -> [卷积层 -> 激活函数 -> 池化层] x N -> 全连接层 -> 输出层**
![[卷积神经网络.png]]
### 卷积层
矩阵的卷积运算：一个大矩阵与一个小矩阵（卷积核）相卷积的结果是，在大矩阵中遍历所有与卷积核尺寸相同的子矩阵，对于每一个子矩阵，与卷积核作元素乘法，并把所得的所有值加起来，再把得到的值放入输出矩阵的对应位置。
例如，对于5×5的输入矩阵与3×3的卷积核矩阵相卷积
$$A=  \begin{bmatrix}
  1 & 2 & 3 & 4 & 5 \\
  6 & 7 & 8 & 9 & 10 \\
  11 & 12 & 13 & 14 & 15 \\
  16 & 17 & 18 & 19 & 20 \\
  21 & 22 & 23 & 24 & 25
  \end{bmatrix},\quad   
  B=\begin{bmatrix}
  0 & 1 & 0 \\
  1 & -4 & 1 \\
  0 & 1 & 0
  \end{bmatrix}$$
  找出$A$的第一个子矩阵，与卷积核作元素乘法，再把各个元素加起来$$  \begin{bmatrix}
  1\times 0 & 2 \times 1 & 3 \times 0\\
  6 \times 1& 7 \times (-4)& 8 \times 1\\
  11 \times 0& 12 \times 1& 13 \times 0\\
  \end{bmatrix}=
  \begin{bmatrix}
0 & 2 & 0\\
6& -28& 8\\
0& 12& 0\\
  \end{bmatrix},\quad 2+6-28+8+12=-4$$
  把这个值填入输出矩阵的左上角（1,1）处，
  继续向右滑动选取子矩阵填入，作类似的运算，把值填入（1,2）处，以此类推
  最终得到$$A* B=  \begin{bmatrix}
  -4 & -6 & -4 \\
  -12 & -24 & -12 \\
  -4 & -6 & -4
  \end{bmatrix}$$
  卷积层中，首先确定一个卷积核，卷积核的具体参数可以通过学习修正。输入数据时，把输入矩阵与卷积核作卷积运算，最终输出一个矩阵作为**特征图**。
  特征图中的每个值代表了原始输入中某个位置是否存在该卷积核所检测的特征。数值越高，匹配度越高。
  - **重要参数**：
    - **深度**：一层中通常使用**多个**不同的卷积核。每个卷积核学习检测一种不同的特征。所有卷积核输出的特征图堆叠在一起，就构成了该卷积层的输出深度。
    - **步长**：卷积核每次滑动的像素数。步长为1每次移动1像素，步长为2每次移动2像素。步长越大，输出特征图尺寸越小。
    - **填充**：有时在输入图像边缘外围填充一圈0，以便控制输出特征图的大小。
### 激活函数
激活函数将卷积层的线性输出进行非线性变换。这是至关重要的，因为如果没有非线性激活函数，无论多少层卷积堆叠，整个网络仍然等价于一个单层线性模型，无法学习复杂的模式。
### 池化层
池化操作的作用是减少数据量，英语中的pool作为动词具有汇集的意思，池化即指将分散的信息汇集、浓缩成一个代表值。
池化（Pooling）层对卷积层输出经过激活函数的特征图作下采样（Downsampling，降低数据点以减少采样率），减少其空间尺寸（高度和宽度），从而：
1. 减少计算量和参数数量，防止过拟合。
2. 使检测到的特征具有一定的平移、旋转和缩放不变性。
3. 聚焦于最显著的特征，扩大后续卷积层的感受野。

与卷积类似，也是一个窗口在特征图上滑动，但不再做点积，而是执行一个简单的统计操作。
常见的池化操作如下：
- 最大池化：取窗口内的最大值。这是最常用的方法，因为它保留了最强烈的特征信号。
- 平均池化：取窗口内的平均值。
### 全连接层
在经过多次卷积和池化后，网络已经提取出了高级的、抽象的特征。全连接层位于网络末端，其功能是将这些分散的特征综合起来，并进行最终的分类或回归。
## 循环神经网络
RNN是处理序列数据的一类强大神经网络，它的设计旨在捕捉数据中的时间依赖性和顺序关系。
RNN的核心思想是引入“记忆”的概念。它能够记住之前处理过的信息，并将其用于当前的计算中RNN通过其循环连接结构，不仅接收当前的输入，还接收一个来自上一个时间步的隐藏状态，这个隐藏状态就像是网络的“记忆”，包含了之前所有输入序列的历史信息。
![[循环神经网络.png]]
对于时刻 $t$：
1. 读取当前输入：$x_t$
2. 读取上一时刻的隐藏状态：$h_{t-1}$
3. 计算当前时刻的新隐藏状态：$h_t = \mathrm{ActivateFunc}(W_{hh}h_{t-1} + W_{xh}x_t + b_h)$
4. 计算当前输出：$y_t = \mathrm{ActivateFunc}(W_{hy}h_t + b_y)$

在每一个时刻，隐藏状态 $h_t$ 都被更新，它承载了从序列开始到当前时间点 $t$ 的所有历史信息。
### 缺陷
- 记忆力差：误差反向传播时，梯度需要沿着时间步连续相乘。如果权重矩阵 $W_{hh}$ 的特征值小于1，梯度会指数级缩小（梯度消失），导致远距离时间步的贡献几乎为零，网络无法学习长期依赖。反之，如果特征值大于1，梯度会指数级增长（梯度爆炸），导致训练不稳定。这导致基本RNN实际上只能记住很短时间步之前的信息，是一个“健忘”的网络。
- 无法并行运算：依赖参数的不断传递，无法利用GPU并行计算的优势。

面对上述问题，长短期记忆网络（Long Short-Term Memory，LSTM）引入了细胞状态和门控机制。
# Transformer
Transformer 由 Google 在 2017 年的论文 《Attention Is All You Need》 中提出。其核心思想是：完全摒弃传统的循环（RNN）和卷积（CNN）结构，仅依赖“自注意力”机制来构建一个强大的序列模型。
## 自注意力机制
自注意力机制是 Transformer 的灵魂。其目的是为序列中的每个单词计算一个“加权特征向量”，这个向量是所有其他单词特征的加权和，权重由单词间的相关性决定。
![[自注意力机制.png]]
计算步骤如下：
1. 对于输入序列的每个词嵌入向量$\vec{a}_{i}$，我们通过三个不同的线性变换，为其生成三个新的向量：
	- **Query**向量：$\vec{q}_{i}=Q \vec{a}_{i}$可以理解为“我正在寻找什么”。
	- **Key**向量：$\vec{k}_{i}=K \vec{a}_{i}$可以理解为“我能提供什么”。
	- **Value**向量：$\vec{v}_{i}=V \vec{a}_{i}$可以理解为“我的实际内容是什么”。
2. 计算注意力分数：计算一个单词的 Query 与所有单词的 Key 的点积，来衡量该单词与各个单词之间的相关性。分数越高，相关性越强。$$\vec{a}_{i}与\vec{a}_{j}的相关性=\vec{q}_{i}\cdot \vec{k}_{j}$$
3. **缩放**：将分数除以 $\sqrt{d_k}$（$d_k$ 是 Key 向量的维度）。这一步是为了在梯度反向传播时保持稳定性，防止点积结果过大导致 Softmax 函数进入梯度极小的饱和区。
4. **计算权重**：对分数进行 Softmax 归一化，得到所有位置的权重系数（和为 1）。这些权重代表了在生成当前输出时，应对其他每个位置投入多少“注意力”。$$c_{ij}=\mathrm{softmax}\left(  \frac{\vec{q}_{i}\cdot \vec{k}_{j}}{\sqrt{ d_{k} }} \right)$$
5. **加权求和**：将权重系数与对应的 Value 向量相乘并求和，得到当前位置的最终输出。$$\vec{b}_{i}=\sum_{j}c_{ij}\vec{v}_{i}$$这是一个承载着上下文信息的新向量。

实际计算中，各个词向量$\vec{a}_{i}$（彼此正交归一）往往组成矩阵$A$参与计算，于是可以将公式改写为：
$$B=\mathrm{Attention}(Q,K,V)A=\mathrm{softmax}\left( \frac{QA(KA)^T}{\sqrt{ d_{k} }} \right)VA=\mathrm{softmax}\left( \frac{QK^T}{\sqrt{ d_{k} }} \right)VA$$
即$$\mathrm{Attention}(Q,K,V)=\mathrm{softmax}\left( \frac{QK^T}{\sqrt{ d_{k} }} \right)V$$
## 多头注意力
单一的注意![[多头注意力.png]]力机制可能不足以捕捉序列中所有类型的有用关系。Transformer 使用了多头注意力。

可以使用$h$个不同的线性变换$Q_{i},K_{i},V_{i}$，计算每一个$Q_{i},K_{i},V_{i}$的注意力，这被称作一个头
$$\mathrm{head}_{i}=\mathrm{Attention}(Q_{i},K_{i},V_{i})$$
为方便表示，我们把其中一组$Q_{i},K_{i},V_{i}$定义为$Q,K,V$，而其他的$Q_{i},K_{i},V_{i}$看作$Q,K,V$经过某个变换所得$Q_{i},K_{i},V_{i}=QW_{i}^Q,KW_{i}^K,VW_{i}^V$
这每一个头都会捕捉词与词之间不同的相互关系，比如一个头可能专注于捕捉语法关系，另一个头可能专注于捕捉指代关系。
将这些头（矩阵）拼接起来形成一个更大的矩阵，然后再乘以一个权重因子$W^O$，用来赋予不同关系以不同的权值，就得到了多头注意力$$\mathrm{MultiHead}(Q,K,V)=\mathrm{Concat}(\mathrm{head}_{1},\dots,\mathrm{head}_{h})W^O$$
其中$\mathrm{Concat}$指的就是矩阵的拼接，可以用库实现，如 TensorFlow 中的 `tf.concat` 函数或 PyTorch 中的 `torch.cat` 函数。
## 位置编码
Transformer 的 Self-Attention 机制存在一个根本缺陷：它天然是置换不变的。如果将输入序列中单词的顺序打乱，Self-Attention 层计算出的输出在内容上不会有任何变化（只是顺序也随之打乱）。因为 Attention 的计算是集合操作，它对输入元素的顺序不敏感。
然而在自然语言（以及大多数序列数据）中，顺序是至关重要的。模型必须知道单词的位置信息才能理解语言的语义和语法结构。因此必须手动将单词在序列中的位置信息注入到模型中，这就需要位置编码（Positional Encoding）。
### 三角编码
对于序列中处于位置 $\text{pos}$ 的单词，其位置编码是一个 $d_{\text{model}}$ 维的向量（与词嵌入的维度相同）。这个向量第 $i$ 个维度的值计算公式如下（$0\leq i < d_{\text{{model}}}/2$）：$$\text{PE}_{(\text{pos},2i)}=\sin\left( \frac{\text{pos}}{10000^{2i/d_{\text{model}}}} \right)$$
$$\text{PE}_{(\text{pos},2i)}=\cos\left( \frac{\text{pos}}{10000^{2i/d_{\text{model}}}} \right)$$
即，位置编码向量的偶数维度（0, 2, 4, ...）使用正弦函数，奇数维度（1, 3, 5, ...）使用余弦函数。每个维度对应一个不同频率的正弦/余弦曲线。随着维度索引 $i$ 的增大，频率在几何地减小。
>使用三角函数编码的原因是：对于任意固定的偏移量 $k$，位置 $pos + k$ 的位置编码可以表示为位置 $pos$ 的位置编码的线性函数。
$$
    \begin{bmatrix}
    \text{PE}_{(\text{pos}+k, 2i)} \\
    \text{PE}_{(\text{pos}+k, 2i+1)}
    \end{bmatrix}
    =
    \begin{bmatrix}
    \cos(k \cdot \omega_i) & \sin(k \cdot \omega_i) \\
    -\sin(k \cdot \omega_i) & \cos(k \cdot \omega_i)
    \end{bmatrix}
    \cdot
    \begin{bmatrix}
    \text{PE}_{(\text{pos}, 2i)} \\
    \text{PE}_{(\text{pos}, 2i+1)}
    \end{bmatrix}
    $$

这是一个不依赖于 $pos$ 的线性变换矩阵，模型可以学会这个变换，从而轻松理解“偏移 $k$”这个概念。

### 将编码融入数据
位置编码与词嵌入向量的整合方式非常简单，就是简单加和起来
$$\text{Input}=\text{TokenEmbedding}+\text{PositionalEncoding}$$
这是因为，在词向量维数足够高的时候，一个概念占据的是一块区域。在和位置编码相加的过程中，相当于是对这块区域作了一个微小的平移，由于空间的自由度是巨大的，此时即使造成了这样的平移，也不太可能将这个概念的区域移动到与另一个不同的概念重合的地方，造成意义的混淆，从而让词向量仍然保持着相对的区分性和独立性。
同时，模型不是被动地接收相加后的结果，而是主动地、有选择地从中提取它所需要的任何信息。模型完全可以学习出一个线性变换，把输入的加和数据分离成词向量和位置编码两部分，之后选取其中有用的信息。
此外，这样的加和同时暗示了一种归纳偏好（Inductive Bias），即认为相信词信息和位置信息是同等重要、可以线性叠加的，并且存在于同一个语义空间中。如果采用拼接，则暗示它们是两种截然不同的、需要独立处理的信息。
### 前馈神经网络
Transformer中的前馈神经网络（Feedforward Neural Network, FFN）用于将从自注意力获取到的全局信息做进一步的处理。
这是一个两层的全连接型神经网络$$\text{FFN}(x) = \mathrm{ReLU}(xW₁ + b₁)\cdot W₂ + b₂$$
第一层$xW_{1}+b_{1}$会将数据从$d_{\text{model}}$（512）的维度投射到更高的维度$d_{ff}$（2048），这层被称为“膨胀层”。因为在高维的空间中，模型更容易学习到复杂的特征，这提供了更多的操作空间。
第一层变换后的数据经过激活函数$\mathrm{ReLU}$为模型引入非线性，从而使模型能拟合复杂的情况。
第二层将经过激活函数的数据再变换回$d_{\text{model}}$维，压缩回原来的尺寸，保障模型的稳定性。
## 模型架构
Transformer的模型架构如下：
![[Transformer模型架构.png]]
### 编码器
在编码器中，输入一段序列（如：等待翻译的英文），经过词嵌入和位置编码，之后将经过多头注意力、残差归一化、前馈神经网络、再残差归一化，得到一个富含上下文信息的隐藏表示序列。
利用这个序列，经过$K,V$的线性变换，然后再把数据传递给解码器。
在解码器中，把输出序列（如：那段英文应该翻译成的中文）经过词嵌入和位置编码以后，要经过一个掩码多头注意力的阶段，这个阶段将覆盖掉当前训练的词语往后的词，以模拟人在思考的过程中依次流水式思考的过程。
然后继续残差归一化，得到的序列经过$Q$的线性变换，与从编码器$K$，$V$数据一起参与多头注意力计算。这个过程相当于把输出作为学习样本，让模型能学习到把输入对应到输出。
之后继续残差归一化、前馈神经网络、线性层，再由$\text{softmax}$转为概率，得到最后的词概率分布，选取最大的词作为输出。
如果跟真实有偏差，就计算代价函数，然后通过反向传播梯度下降即可。