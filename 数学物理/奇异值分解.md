#线性代数 
奇异值分解（Singular Value Decomposition）简称SVD，是线性代数中一种极其重要且应用广泛的矩阵分解方法。
任何$m\times n$的实矩阵$A$都可以分解成三个特殊的矩阵相乘的形式$$A=U\Sigma V^T$$其中$U,V$分别是$m\times m$和$n\times n$的正交矩阵（若元素是复数，则为酉矩阵），而$\Sigma$是$m\times n$的对角矩阵。
$U$的列称为*左奇异向量*，可看作输出空间$U$的一组标准正交基。
$V$的列称为*右奇异向量*，可看作输入空间$V$的一组标准正交基。
$\Sigma$对角线上的元素称为奇异值，通常按从大到小排列。**奇异值一定是非负实数**。
整个过程可以视作：
1. 初始化输入空间$V$：将标准正交基下的向量用$n$维输入空间$V$的标准正交基$(v_{1},v_{2},\dots,v_{n})$表示（发生镜像或旋转）。
2. 缩放$\Sigma$：沿着$v_{i}$的方向按照对应的奇异值$\sigma_{i}$进行伸缩变换。
3. 传输到输出空间$U$：将所得结果用$m$维输出空间$U$的标准正交基$(u_{1},u_{2},\dots,u_{m})$表示，输出在$U$中的坐标。

# 奇异值分解的计算
用上面的分解式计算$A^TA$可以得到$$A^TA=V\Sigma U^TU\Sigma V^T=V\Sigma^2V^T=V\Sigma^2V^{-1}$$所以可以用[[矩阵对角化]]的方式计算奇异值分解。
同样可以得到$AA^T=U\Sigma U^{-1}$。
1. 计算$A^TA$的本征值和本征向量。由于$A^TA$是实对称矩阵，所以本征值必然都非负，可以开根，就得到了奇异值。得到的本征向量$(v_{1},v_{2},\dots,v_{n})$就构成了$V$。
2. 通过$AV=U\Sigma$，计算$$u_{i}=\frac{1}{\sigma_{i}}Av_{i}$$

实际例子$$A = \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 1 \end{bmatrix}=U\Sigma V^T= \begin{bmatrix} \frac{1}{\sqrt{6}} & \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{3}} \\ \frac{1}{\sqrt{6}} & -\frac{1}{\sqrt{2}} & \frac{1}{\sqrt{3}} \\ \frac{2}{\sqrt{6}} & 0 & -\frac{1}{\sqrt{3}} \end{bmatrix}\begin{bmatrix} \sqrt{3} & 0 \\ 0 & 1 \\ 0 & 0 \end{bmatrix}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}^T$$
# 奇异值分解与秩
因为正交变换不改变矩阵的秩，所以$$\mathrm{rank}(A)=\mathrm{rank}(\Sigma)$$故非零奇异值的个数等于原矩阵秩的个数。
奇异值分解为我们提供了一个更加连续的视角。假如一个矩阵经过奇异值分解后得到的$\Sigma$为$$\begin{pmatrix}
1 &  0\\
0 & 0.001
\end{pmatrix}$$虽然它严格来说是一个满秩的矩阵，但我们可以发现它与非满秩的矩阵有非常相似的特征，也就是经过变换后数据在某些方向上会被强烈压缩。
